{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66acfb85-2b23-40e3-b57d-4af082868917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from deap import base, creator, tools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ee362f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.3 #threshold di discriminazione\n",
    "egoradius = 2 #Per link da aggiungere - raggio dell'egonetwork\n",
    "delete = 0.5 #Per link da eliminare - top % con betweeness bassa rimovibili\n",
    "attr_name = 'gender'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "120af3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = Solo aggiunta\n",
    "# 1 = Solo rimozione\n",
    "# 2 = Entrambe\n",
    "mode = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "542c46ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness = 'nodes'\n",
    "#marg = marginalization score => somma abs(marg) dei singoli nodi / n.nodi => [0, 1]\n",
    "#nodes = marginalized nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17a88840",
   "metadata": {},
   "outputs": [],
   "source": [
    "glob = True\n",
    "\n",
    "n_ran_nodes = 300\n",
    "n_poss = 250\n",
    "n_weak = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30447bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_missing = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2007c150",
   "metadata": {},
   "source": [
    "# AMARE MI VA- Attribute-aware MARginalization Estimator with MIssing VAlues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c890509-942f-4750-ba01-98f1e5fcaecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded net\n",
      "loaded attributes\n"
     ]
    }
   ],
   "source": [
    "g = nx.Graph()\n",
    "g.name = 'copenhagen'\n",
    "with open('bt_symmetric.csv') as f:\n",
    "    for l in f.readlines()[1:]:\n",
    "        tid, a, b, rssi = l.rstrip().split(',')\n",
    "        g.add_edge(int(a),int(b), tid=tid)\n",
    "print('loaded net')\n",
    "\n",
    "attrs = {n: None for n in g.nodes()} # also fix missing data\n",
    "with open('genders.csv') as f:\n",
    "    for l in f.readlines()[1:]:\n",
    "        node, gender = l.rstrip().split(',')\n",
    "        attrs[int(node)] = gender\n",
    "    nx.set_node_attributes(g, attrs, name=attr_name)\n",
    "print('loaded attributes')\n",
    "\n",
    "missing = []\n",
    "for n in attrs:\n",
    "    if attrs[n] is None:\n",
    "        missing.append(n)\n",
    "\n",
    "#g.remove_nodes_from(missing)\n",
    "#print('unlabeled removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d6e85f7-0c4e-41b3-838f-6b680104bc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: copenhagen\n",
      "Type: Graph\n",
      "Number of nodes: 708\n",
      "Number of edges: 80886\n",
      "Average degree: 228.4915\n"
     ]
    }
   ],
   "source": [
    "print(nx.info(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d261cd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16e79485",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = nx.get_node_attributes(g, attr_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a47de09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_individual(missing):\n",
    "    individual = []\n",
    "    for e in missing:\n",
    "        individual.append(random.randint(0,1)) #1 = aggiunto/rimosso; 0 = do nothing\n",
    "    return individual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46f291fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(individual, g, return_net):\n",
    "    individual = individual[0] #<- because DEAP\n",
    "    for node, attr in zip(missing, individual):\n",
    "        attrs[node] = str(attr)\n",
    "    \n",
    "    sizes = dict(Counter(list(attrs.values())))\n",
    "    sizes['0'] = sizes['0'] / (len(g))\n",
    "    sizes['1'] = sizes['1'] / (len(g))\n",
    "    weights = dict(Counter(list(attrs.values())))\n",
    "    weights['0'] = 1 - sizes['0']\n",
    "    weights['1'] = 1 - sizes['1']\n",
    "    \n",
    "    marg_dict = dict()\n",
    "\n",
    "    for node in g.nodes():\n",
    "        attr = attrs[node]\n",
    "\n",
    "        # COMPUTE MARGINALIZATION\n",
    "        marg = 0\n",
    "        egonet = list(g.neighbors(node)) + [node]\n",
    "        egonet_attrs = [attrs[n] for n in egonet]\n",
    "\n",
    "        count = dict(Counter(egonet_attrs))[attr]\n",
    "        size = len(egonet_attrs)\n",
    "\n",
    "        if size > 2:\n",
    "            marg = ((count * weights[attr] / (count * weights[attr] + (size-count)* (1 - weights[attr]))) - 0.5) * 2\n",
    "        else:\n",
    "            marg = 0\n",
    "\n",
    "        marg_dict[node] = marg\n",
    "\n",
    "    disc_nodes = [k for k,v in marg_dict.items() if abs(v) > threshold]\n",
    "\n",
    "    ov_marg = np.mean([abs(v) for v in marg_dict.values()]) #network marginalization score\n",
    "    base_marg = [abs(v) for k, v in marg_dict.items() if k not in disc_nodes]\n",
    "    \n",
    "    if return_net:        \n",
    "        print(\"=== STATS ===\")\n",
    "        print(\"Marginalized nodes:\", len(disc_nodes))\n",
    "        print(\"Global Discrimination:\", len(disc_nodes) * 100 / len(g.nodes()))\n",
    "        print(\"Overall Marginalization Score:\", ov_marg)\n",
    "        print(\"Marginalization Score w/o Marg nodes:\", np.mean(base_marg))\n",
    "        sns.kdeplot(list(marg_dict.values()))\n",
    "\n",
    "        return weights, marg_dict, disc_nodes, ov_marg, base_marg\n",
    "    \n",
    "    if fitness == 'marg':\n",
    "        return ov_marg, len(disc_nodes)\n",
    "    elif fitness == 'nodes':\n",
    "        return len(disc_nodes), ov_marg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cc81827",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_net = False #if True, eva function returns the fair network. INSIDE THE GA, IT MUST BE FALSE\n",
    "\n",
    "creator.create(\"Fitness\", base.Fitness, weights=(-1.0,-1.0)) # <- -1 perché vogliamo minimizzare la fitness\n",
    "creator.create(\"Individual\", list, fitness=creator.Fitness) #<- l'individuo è definito come lista\n",
    "\n",
    "toolbox = base.Toolbox() #creiamo il toolbox\n",
    "\n",
    "toolbox.register(\"random_individual\", random_individual, missing) \n",
    "#\"nome_della_funzione per deap\", nome_della_funzione vera e propria di python, parametri che passi alla funzione\n",
    "\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, \n",
    "                 toolbox.random_individual, n=1) \n",
    "# n = numero di individui nella popolazione. Lasciamo 1\n",
    "\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate, g=g, return_net=return_net) #funzione di valutazione. Vedi quanto detto sopra\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint) #funzione di crossover\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05) #funzione di mutazione custom\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "#tools.selNSGA2) #funzione di selezione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc829d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 673/673 [00:00<00:00, 42017.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unlabeled removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if remove_missing:\n",
    "    g.remove_nodes_from(missing)\n",
    "    print('unlabeled removed')\n",
    "    \n",
    "    attrs = nx.get_node_attributes(g, attr_name)\n",
    "    \n",
    "    sizes = dict(Counter(list(attrs.values())))\n",
    "    sizes['0'] = sizes['0'] / (len(g) + len(missing))\n",
    "    sizes['1'] = sizes['1'] / (len(g) + len(missing))\n",
    "    weights = dict(Counter(list(attrs.values())))\n",
    "    weights['0'] = 1 - sizes['0']\n",
    "    weights['1'] = 1 - sizes['1']\n",
    "    \n",
    "    marg_dict = dict()\n",
    "\n",
    "    for node in tqdm(g.nodes()):\n",
    "        attr = attrs[node]\n",
    "\n",
    "        # COMPUTE MARGINALIZATION\n",
    "        marg = 0\n",
    "        egonet = list(g.neighbors(node)) + [node]\n",
    "        egonet_attrs = [attrs[n] for n in egonet]\n",
    "\n",
    "        count = dict(Counter(egonet_attrs))[attr]\n",
    "        size = len(egonet_attrs)\n",
    "\n",
    "        if size > 2:\n",
    "            marg = ((count * weights[attr] / (count * weights[attr] + (size-count)* (1 - weights[attr]))) - 0.5) * 2\n",
    "        else:\n",
    "            marg = 0\n",
    "\n",
    "        marg_dict[node] = marg\n",
    "\n",
    "    disc_nodes = [k for k,v in marg_dict.items() if abs(v) > threshold]\n",
    "    disc = len(disc_nodes)\n",
    "\n",
    "    ov_marg = np.mean([abs(v) for v in marg_dict.values()]) #network marginalization score\n",
    "    base_marg = [abs(v) for k, v in marg_dict.items() if k not in disc_nodes] # marg score w/o marg nodes. used in eva function\n",
    "\n",
    "else:\n",
    "    print('Fitness:', fitness)\n",
    "    NUM_GENERATIONS = 50 #numero di generazioni\n",
    "    POPULATION_SIZE = 150 #popolazione per gen\n",
    "\n",
    "    CXPB, MUTPB = 0.5, 0.25 #crossover e mutation probability\n",
    "\n",
    "    n_HOF = 10 #top soluzioni da ritornare (la \"Hall of Fame\" di DEAP è il set di tutte le top n soluzioni)\n",
    "\n",
    "    pop = toolbox.population(n=POPULATION_SIZE)\n",
    "\n",
    "    hof = tools.HallOfFame(n_HOF)\n",
    "\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values[0])   \n",
    "    stats.register('min', np.min, axis = 0)\n",
    "    stats.register('avg', np.mean, axis = 0)\n",
    "\n",
    "    logbook = tools.Logbook()\n",
    "    logbook.header = ['gen', 'nevals'] + stats.fields\n",
    "\n",
    "    invalid_individuals = [ind for ind in pop if not ind.fitness.valid]\n",
    "    fitnesses = toolbox.map(toolbox.evaluate, invalid_individuals)\n",
    "    for ind, fit in zip(invalid_individuals, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    hof.update(pop)\n",
    "    hof_size = len(hof.items)\n",
    "\n",
    "    record = stats.compile(pop)\n",
    "    logbook.record(gen=0, best=\"-\", nevals=len(invalid_individuals), **record)\n",
    "    print(logbook.stream)\n",
    "\n",
    "    for gen in range(1, NUM_GENERATIONS + 1):\n",
    "\n",
    "                # Select the next generation individuals\n",
    "        offspring = toolbox.select(pop, len(pop))\n",
    "        # Clone the selected individuals\n",
    "        offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "\n",
    "        # Apply crossover and mutation on the offspring\n",
    "        for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "            if random.random() < CXPB:\n",
    "                toolbox.mate(child1[0], child2[0])\n",
    "                del child1.fitness.values\n",
    "                del child2.fitness.values\n",
    "\n",
    "        for mutant in offspring:\n",
    "            if random.random() < MUTPB:\n",
    "                toolbox.mutate(mutant[0])\n",
    "                del mutant.fitness.values\n",
    "\n",
    "\n",
    "        # Evaluate the individuals with an invalid fitness\n",
    "        invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "        fitnesses = map(toolbox.evaluate, invalid_ind)\n",
    "        for ind, fit in zip(invalid_ind, fitnesses):\n",
    "            ind.fitness.values = fit\n",
    "\n",
    "        # Update the hall of fame with the generated individuals\n",
    "        hof.update(offspring)\n",
    "\n",
    "        # Replace the current population by the offspring\n",
    "        pop[:] = offspring\n",
    "\n",
    "        # Append the current generation statistics to the logbook\n",
    "        record = stats.compile(pop) if stats else {}\n",
    "        logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "        print(logbook.stream)\n",
    "\n",
    "\n",
    "    hof.update(pop) # la HoF è aggiornata con la nuova popolazione (o meglio, i suoi individui migliori w.r.t. fitness)\n",
    "\n",
    "    plt.figure(1)\n",
    "\n",
    "    minFitnessValues, meanFitnessValues = logbook.select(\"min\", \"avg\")\n",
    "    plt.figure(2)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    #plt.plot(maxFitnessValues, color='red')\n",
    "    plt.plot(minFitnessValues, color='blue')\n",
    "    plt.plot(meanFitnessValues, color='green')\n",
    "    plt.xlabel('Generation')\n",
    "    if fitness == 'nodes':\n",
    "        plt.ylabel('Marginalized Nodes')\n",
    "        plt.title('Avg and Min Marginalized Nodes')\n",
    "    elif fitness == 'marg':\n",
    "        plt.ylabel('Marginalization Score')\n",
    "        plt.title('Avg and Min Marginalization Score')    \n",
    "    # show both plots:\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    #return hof.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83a2d02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if remove_missing == False:\n",
    "    weights, marg_dict, disc_nodes, ov_marg, base_marg = evaluate(hof.items[0], g, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba0fd357-e21c-4da5-8448-eeb01a182196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if glob == False:\n",
    "    ran_nodes = random.sample(list(g.nodes()), n_ran_nodes)\n",
    "    ran_marg = [abs(v) for k, v in marg_dict.items() if k not in ran_nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "16f335af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 47/47 [00:11<00:00,  4.25it/s]\n"
     ]
    }
   ],
   "source": [
    "if mode == 1:\n",
    "    possible_links = [] \n",
    "else:\n",
    "    plausible = nx.Graph() # stores plausible links\n",
    "\n",
    "    if glob:\n",
    "        for node in tqdm(disc_nodes):\n",
    "            egonet = list(g.neighbors(node)) + [node]\n",
    "            egonet2 = nx.ego_graph(g, node, center=True, radius=egoradius)\n",
    "            egonet2.remove_nodes_from(egonet)\n",
    "            for n in egonet2.nodes():\n",
    "                if node != n and n in disc_nodes:\n",
    "                    if marg_dict[node] > 0:\n",
    "                        if attrs[n] != attrs[node]:\n",
    "                            plausible.add_edge(node, n)\n",
    "                    elif marg_dict[node] < 0:\n",
    "                        if attrs[n] == attrs[node]:\n",
    "                            plausible.add_edge(node, n)         \n",
    "                    else:\n",
    "                        print(\"ERROR #01\")\n",
    "        possible_links = list(plausible.edges())\n",
    "        \n",
    "    else:\n",
    "        for node in tqdm(ran_nodes):\n",
    "            egonet = list(g.neighbors(node)) + [node]\n",
    "            egonet2 = nx.ego_graph(g, node, center=True, radius=egoradius)\n",
    "            egonet2.remove_nodes_from(egonet)\n",
    "            for n in egonet2.nodes():\n",
    "                if node != n:\n",
    "                    plausible.add_edge(node, n)\n",
    "        possible_links = random.sample(list(plausible.edges()), n_poss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bebeac8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75124/75124 [00:00<00:00, 1766087.08it/s]\n"
     ]
    }
   ],
   "source": [
    "if mode == 0:\n",
    "    weak_links = []\n",
    "else:\n",
    "    #Betweenness centrality su archi\n",
    "    betweenness = nx.edge_betweenness_centrality(g) #dizionario di archi con score di BW centrality\n",
    "\n",
    "    marg_betweenness = dict()\n",
    "    \n",
    "    if glob:\n",
    "        for k, v in tqdm(betweenness.items()):\n",
    "            if k[0] in disc_nodes and k[1] in disc_nodes:\n",
    "                if marg_dict[k[0]] > 0:\n",
    "                    if attrs[k[0]] == attrs[k[1]]:\n",
    "                        marg_betweenness[k] = v\n",
    "                elif marg_dict[k[0]] < 0:\n",
    "                    if attrs[k[0]] != attrs[k[1]]:\n",
    "                        marg_betweenness[k] = v\n",
    "                else:\n",
    "                    print (\"ERROR #02\")\n",
    "        marg_betweenness = dict(sorted(marg_betweenness.items(), key=lambda item: item[1]))\n",
    "        weak_links = list(marg_betweenness.keys())[:round(len(marg_betweenness) * delete)]\n",
    "        \n",
    "    else:\n",
    "        for k, v in tqdm(betweenness.items()):\n",
    "            if k[0] in ran_nodes and k[1] in ran_nodes:\n",
    "                    marg_betweenness[k] = v\n",
    "\n",
    "        marg_betweenness = dict(sorted(marg_betweenness.items(), key=lambda item: item[1]))\n",
    "        weak_links = list(marg_betweenness.keys())[:n_weak]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a452e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = possible_links + weak_links #tutti i links con cui il GA opera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3820b77d",
   "metadata": {},
   "source": [
    "# MARK - MArginalization Reducer using linK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7bcceb0-989b-4d0d-a8a2-506f6aeaa4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_individual(links):\n",
    "    individual = []\n",
    "    for e in links:\n",
    "        individual.append(random.randint(0,1)) #1 = aggiunto/rimosso; 0 = do nothing\n",
    "    return individual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ae8f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(individual, g, return_net):\n",
    "    individual = individual[0] #<- because DEAP\n",
    "    nodes = 0 #amount of marginalized nodes in fair network\n",
    "    \n",
    "    if glob:\n",
    "        fair_marg = base_marg.copy() #marginalization score of fair network\n",
    "    else:\n",
    "        fair_marg = ran_marg.copy()\n",
    "        \n",
    "    eva_g = copy.deepcopy(g)\n",
    "    indexes = [i for i, j in enumerate(individual) if j == 1]\n",
    "    new_links = [links[i] for i in indexes]\n",
    "\n",
    "    for l in new_links:\n",
    "        if l in possible_links:\n",
    "            eva_g.add_edge(l[0], l[1])\n",
    "        elif l in weak_links:\n",
    "            eva_g.remove_edge(l[0], l[1])\n",
    "            \n",
    "            \n",
    "    if glob:\n",
    "        for node in disc_nodes:\n",
    "            \n",
    "            attr = attrs[node] ###aggiunto\n",
    "\n",
    "            marg = 0\n",
    "            egonet = list(eva_g.neighbors(node)) + [node]\n",
    "            egonet_attrs = [attrs[n] for n in egonet]\n",
    "            count = dict(Counter(egonet_attrs))[attr]\n",
    "            size = len(egonet)\n",
    "            if size > 2:\n",
    "                marg = ((count * weights[attr] / (count * weights[attr] + (size-count)* (1 - weights[attr]))) - 0.5) * 2\n",
    "                fair_marg.append(abs(marg))\n",
    "                if abs(marg) > threshold:\n",
    "                    nodes += 1\n",
    "    \n",
    "    else:\n",
    "        nodes = len(disc_nodes)\n",
    "        for node in ran_nodes:\n",
    "            \n",
    "            \n",
    "            attr = attrs[node] ###aggiunto\n",
    "\n",
    "            marg = 0\n",
    "            egonet = list(eva_g.neighbors(node)) + [node]\n",
    "            egonet_attrs = [attrs[n] for n in egonet]\n",
    "            count = dict(Counter(egonet_attrs))[attr]\n",
    "            size = len(egonet)\n",
    "            if size > 2:\n",
    "                marg = ((count * weights[attr] / (count * weights[attr] + (size-count)* (1 - weights[attr]))) - 0.5) * 2\n",
    "                fair_marg.append(abs(marg))\n",
    "                if node in disc_nodes:\n",
    "                    if abs(marg) < threshold:\n",
    "                        nodes = nodes - 1\n",
    "                else:\n",
    "                    if abs(marg) > threshold:\n",
    "                        nodes = nodes + 1          \n",
    "        \n",
    "    budget = sum(individual)\n",
    "    \n",
    "    if return_net:\n",
    "        return nodes, np.mean(fair_marg), budget, eva_g\n",
    "    \n",
    "    if fitness == 'nodes':      \n",
    "        return nodes, budget\n",
    "    elif fitness == 'marg':\n",
    "        return np.mean(fair_marg), budget\n",
    "    else:\n",
    "        print (\"ERROR #03\")\n",
    "        \n",
    "\n",
    "\n",
    "    #Fitness 1: nodi marginalizzati rimasti\n",
    "    #Fitness 2: link usati\n",
    "    \n",
    "    #A parità di nodi marginalizzati (il meno possibile), la soluzione con meno link usati è la migliore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cf6791b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/federico/miniforge3/envs/tf/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'Fitness' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/Users/federico/miniforge3/envs/tf/lib/python3.8/site-packages/deap/creator.py:138: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    }
   ],
   "source": [
    "return_net = False #if True, eva function returns the fair network. INSIDE THE GA, IT MUST BE FALSE\n",
    "\n",
    "creator.create(\"Fitness\", base.Fitness, weights=(-1.0,-1.0)) # <- -1 perché vogliamo minimizzare la fitness\n",
    "creator.create(\"Individual\", list, fitness=creator.Fitness) #<- l'individuo è definito come lista\n",
    "\n",
    "toolbox = base.Toolbox() #creiamo il toolbox\n",
    "\n",
    "toolbox.register(\"random_individual\", random_individual, links) \n",
    "#\"nome_della_funzione per deap\", nome_della_funzione vera e propria di python, parametri che passi alla funzione\n",
    "\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, \n",
    "                 toolbox.random_individual, n=1) \n",
    "# n = numero di individui nella popolazione. Lasciamo 1\n",
    "\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate, g=g, return_net=return_net) #funzione di valutazione. Vedi quanto detto sopra\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint) #funzione di crossover\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05) #funzione di mutazione custom\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "#tools.selNSGA2) #funzione di selezione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6fac1a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marg nodes: 47 · Marg Score: 0.1453457021907056 · Available links: 457\n",
      "Fitness: nodes\n",
      "gen\tnevals\tmin\tavg    \n",
      "0  \t150   \t9  \t14.0333\n",
      "1  \t90    \t8  \t12.3867\n",
      "2  \t91    \t6  \t11.3067\n",
      "3  \t90    \t6  \t10.2933\n",
      "4  \t102   \t6  \t9.33333\n",
      "5  \t97    \t6  \t8.32   \n",
      "6  \t83    \t5  \t7.58667\n",
      "7  \t88    \t5  \t7.14   \n",
      "8  \t93    \t5  \t6.78   \n"
     ]
    }
   ],
   "source": [
    "print('Marg nodes:', len(disc_nodes), '· Marg Score:', ov_marg, '· Available links:', len(links))\n",
    "print('Fitness:', fitness)\n",
    "NUM_GENERATIONS = 30 #numero di generazioni\n",
    "POPULATION_SIZE = 150 #popolazione per gen\n",
    "\n",
    "CXPB, MUTPB = 0.5, 0.25 #crossover e mutation probability\n",
    "\n",
    "n_HOF = 10 #top soluzioni da ritornare (la \"Hall of Fame\" di DEAP è il set di tutte le top n soluzioni)\n",
    "\n",
    "pop = toolbox.population(n=POPULATION_SIZE)\n",
    "\n",
    "hof = tools.HallOfFame(n_HOF)\n",
    "\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values[0])   \n",
    "stats.register('min', np.min, axis = 0)\n",
    "stats.register('avg', np.mean, axis = 0)\n",
    "\n",
    "logbook = tools.Logbook()\n",
    "logbook.header = ['gen', 'nevals'] + stats.fields\n",
    "\n",
    "invalid_individuals = [ind for ind in pop if not ind.fitness.valid]\n",
    "fitnesses = toolbox.map(toolbox.evaluate, invalid_individuals)\n",
    "for ind, fit in zip(invalid_individuals, fitnesses):\n",
    "    ind.fitness.values = fit\n",
    "\n",
    "hof.update(pop)\n",
    "hof_size = len(hof.items)\n",
    "\n",
    "record = stats.compile(pop)\n",
    "logbook.record(gen=0, best=\"-\", nevals=len(invalid_individuals), **record)\n",
    "print(logbook.stream)\n",
    "\n",
    "for gen in range(1, NUM_GENERATIONS + 1):\n",
    "\n",
    "            # Select the next generation individuals\n",
    "    offspring = toolbox.select(pop, len(pop))\n",
    "    # Clone the selected individuals\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "\n",
    "    # Apply crossover and mutation on the offspring\n",
    "    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if random.random() < CXPB:\n",
    "            toolbox.mate(child1[0], child2[0])\n",
    "            del child1.fitness.values\n",
    "            del child2.fitness.values\n",
    "\n",
    "    for mutant in offspring:\n",
    "        if random.random() < MUTPB:\n",
    "            toolbox.mutate(mutant[0])\n",
    "            del mutant.fitness.values\n",
    "\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    fitnesses = map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    # Update the hall of fame with the generated individuals\n",
    "    hof.update(offspring)\n",
    "\n",
    "    # Replace the current population by the offspring\n",
    "    pop[:] = offspring\n",
    "\n",
    "    # Append the current generation statistics to the logbook\n",
    "    record = stats.compile(pop) if stats else {}\n",
    "    logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "    print(logbook.stream)\n",
    "\n",
    "\n",
    "hof.update(pop) # la HoF è aggiornata con la nuova popolazione (o meglio, i suoi individui migliori w.r.t. fitness)\n",
    "\n",
    "plt.figure(1)\n",
    "\n",
    "minFitnessValues, meanFitnessValues = logbook.select(\"min\", \"avg\")\n",
    "plt.figure(2)\n",
    "sns.set_style(\"whitegrid\")\n",
    "#plt.plot(maxFitnessValues, color='red')\n",
    "plt.plot(minFitnessValues, color='blue')\n",
    "plt.plot(meanFitnessValues, color='green')\n",
    "plt.xlabel('Generation')\n",
    "if fitness == 'nodes':\n",
    "    plt.ylabel('Marginalized Nodes')\n",
    "    plt.title('Avg and Min Marginalized Nodes')\n",
    "elif fitness == 'marg':\n",
    "    plt.ylabel('Marginalization Score')\n",
    "    plt.title('Avg and Min Marginalization Score')    \n",
    "# show both plots:\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#return hof.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a0c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = hof.items[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb484a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_nodes, fair_score, fair_budget, fair_net = evaluate([best], g, True)\n",
    "\n",
    "print (\"Marg Nodes:\", fair_nodes, '· Prev:', len(disc_nodes))\n",
    "print (\"Marg Score:\", fair_score, '· Prev:', ov_marg)\n",
    "print (\"Links:\", fair_net.number_of_edges(), '· Prev:', g.number_of_edges())\n",
    "if mode == 0:\n",
    "    print (\"Added links:\", fair_budget)\n",
    "elif mode == 1:\n",
    "    print (\"Removed links:\", fair_budget)\n",
    "elif mode == 2:\n",
    "    print (\"Modified links:\", fair_budget)\n",
    "    added = fair_net.number_of_edges() - g.number_of_edges()\n",
    "    print (\"-- of which added:\", added)\n",
    "    print (\"-- of which removed:\", fair_budget - added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002ff23b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad555008",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RandNet - A Random Benchmark for FairNet\")\n",
    "nodes_ran = []\n",
    "score_ran = []\n",
    "c = 0\n",
    "while c < 100:\n",
    "    ran = random_individual(links)\n",
    "    fair_nodes, fair_score, fair_budget, fair_net = evaluate([ran], g, True)\n",
    "    nodes_ran.append(fair_nodes)\n",
    "    score_ran.append(fair_score)\n",
    "    c = c+1\n",
    "\n",
    "print(\"- Marg nodes\")\n",
    "print(\"Avg:\", np.mean(nodes_ran), \"· Min:\", min(nodes_ran))\n",
    "print(\"- Marg score\")\n",
    "print(\"Avg:\", np.mean(score_ran), \"· Min:\", min(score_ran))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca52e31c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
