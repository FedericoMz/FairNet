{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66acfb85-2b23-40e3-b57d-4af082868917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "from deap import base, creator, tools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee362f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.3 #threshold di discriminazione\n",
    "egoradius = 2 #Per link da aggiungere - raggio dell'egonetwork\n",
    "delete = 0.5 #Per link da eliminare - top % con betweeness bassa rimovibili\n",
    "attr_name = 'gender'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120af3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = Solo aggiunta\n",
    "# 1 = Solo rimozione\n",
    "# 2 = Entrambe\n",
    "mode = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542c46ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitness = 'marg'\n",
    "#marg = marginalization score\n",
    "#nodes = marginalized nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2007c150",
   "metadata": {},
   "source": [
    "# AMARE - Attribute-aware MARginalization Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c890509-942f-4750-ba01-98f1e5fcaecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = nx.Graph()\n",
    "g.name = 'copenhagen'\n",
    "with open('bt_symmetric.csv') as f:\n",
    "    for l in f.readlines()[1:]:\n",
    "        tid, a, b, rssi = l.rstrip().split(',')\n",
    "        g.add_edge(int(a),int(b), tid=tid)\n",
    "print('loaded net')\n",
    "\n",
    "attrs = {n: None for n in g.nodes()} # also fix missing data\n",
    "with open('genders.csv') as f:\n",
    "    for l in f.readlines()[1:]:\n",
    "        node, gender = l.rstrip().split(',')\n",
    "        attrs[int(node)] = gender\n",
    "    nx.set_node_attributes(g, attrs, name=attr_name)\n",
    "print('loaded attributes')\n",
    "\n",
    "to_remove = []\n",
    "for n in attrs:\n",
    "    if attrs[n] is None:\n",
    "        to_remove.append(n)\n",
    "\n",
    "g.remove_nodes_from(to_remove)\n",
    "print('unlabeled removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6e85f7-0c4e-41b3-838f-6b680104bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.info(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e79485",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = nx.get_node_attributes(g, attr_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a55fed-fc80-4768-a6ab-0d6b989fe9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#g = nx.convert_node_labels_to_integers(g)\n",
    "sizes = dict(Counter(list(attrs.values())))\n",
    "sizes['0'] = sizes['0'] / (len(g))\n",
    "sizes['1'] = sizes['1'] / (len(g))\n",
    "weights = dict(Counter(list(attrs.values())))\n",
    "weights['0'] = 1 - sizes['0']\n",
    "weights['1'] = 1 - sizes['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0fd357-e21c-4da5-8448-eeb01a182196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "marg_dict = dict()\n",
    "\n",
    "for node in tqdm(g.nodes()):\n",
    "    attr = attrs[node]\n",
    "    \n",
    "    # COMPUTE MARGINALIZATION\n",
    "    marg = 0\n",
    "    egonet = list(g.neighbors(node)) + [node]\n",
    "    egonet_attrs = [attrs[n] for n in egonet]\n",
    "    \n",
    "    count = dict(Counter(egonet_attrs))[attr]\n",
    "    size = len(egonet_attrs)\n",
    "    \n",
    "    if size > 2:\n",
    "        marg = ((count * weights[attr] / (count * weights[attr] + (size-count)* (1 - weights[attr]))) - 0.5) * 2\n",
    "    else:\n",
    "        marg = 0\n",
    "    \n",
    "    marg_dict[node] = marg\n",
    "\n",
    "disc_nodes = [k for k,v in marg_dict.items() if abs(v) > threshold]\n",
    "disc = len(disc_nodes)\n",
    "\n",
    "ov_marg = np.mean([abs(v) for v in marg_dict.values()]) #network marginalization score\n",
    "base_marg = [abs(v) for k, v in marg_dict.items() if k not in disc_nodes] # marg score w/o marg nodes. used in eva function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a11d649",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== STATS ===\")\n",
    "print(\"Marginalized nodes:\", disc)\n",
    "print(\"Global Discrimination:\", disc * 100 / len(g.nodes()))\n",
    "print(\"Overall Marginalization Score:\", ov_marg)\n",
    "print(\"Marginalization Score w/o Marg nodes:\", np.mean(base_marg))\n",
    "\n",
    "sns.kdeplot(list(marg_dict.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccebf7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f335af",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 1:\n",
    "    possible_links = []\n",
    "else:\n",
    "    plausible = nx.Graph() # stores plausible links\n",
    "\n",
    "    for node in tqdm(disc_nodes):\n",
    "        egonet = list(g.neighbors(node)) + [node]\n",
    "        egonet2 = nx.ego_graph(g, node, center=True, radius=egoradius)\n",
    "        egonet2.remove_nodes_from(egonet)\n",
    "        for n in egonet2.nodes():\n",
    "            if node != n and n in disc_nodes:\n",
    "                if marg_dict[node] > 0:\n",
    "                    if attrs[n] != attrs[node]:\n",
    "                        plausible.add_edge(node, n)\n",
    "                elif marg_dict[node] < 0:\n",
    "                    if attrs[n] == attrs[node]:\n",
    "                        plausible.add_edge(node, n)         \n",
    "                else:\n",
    "                    print(\"ERROR #01\")\n",
    "\n",
    "    possible_links = list(plausible.edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebeac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode == 0:\n",
    "    weak_links = []\n",
    "else:\n",
    "    #Betweenness centrality su archi\n",
    "    betweenness = nx.edge_betweenness_centrality(g) #dizionario di archi con score di BW centrality\n",
    "\n",
    "    marg_betweenness = dict()\n",
    "    for k, v in tqdm(betweenness.items()):\n",
    "        if k[0] in disc_nodes and k[1] in disc_nodes:\n",
    "            if marg_dict[k[0]] > 0:\n",
    "                if attrs[k[0]] == attrs[k[1]]:\n",
    "                    marg_betweenness[k] = v\n",
    "            elif marg_dict[k[0]] < 0:\n",
    "                if attrs[k[0]] != attrs[k[1]]:\n",
    "                    marg_betweenness[k] = v\n",
    "            else:\n",
    "                print (\"ERROR #02\")\n",
    "\n",
    "    marg_betweenness = dict(sorted(marg_betweenness.items(), key=lambda item: item[1]))\n",
    "    weak_links = list(marg_betweenness.keys())[:round(len(marg_betweenness) * delete)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a452e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = possible_links + weak_links #tutti i links con cui il GA opera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f5a6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3820b77d",
   "metadata": {},
   "source": [
    "# MARK - MArginalization Reducer using linK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bcceb0-989b-4d0d-a8a2-506f6aeaa4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_individual(links):\n",
    "    individual = []\n",
    "    for e in links:\n",
    "        individual.append(random.randint(0,1)) #1 = aggiunto/rimosso; 0 = do nothing\n",
    "    return individual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae8f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(individual, g, return_net):\n",
    "    individual = individual[0] #<- because DEAP\n",
    "    nodes = 0 #amount of marginalized nodes in fair network\n",
    "    fair_marg = base_marg.copy() #marginalization score of fair network\n",
    "    eva_g = copy.deepcopy(g)\n",
    "    indexes = [i for i, j in enumerate(individual) if j == 1]\n",
    "    new_links = [links[i] for i in indexes]\n",
    "\n",
    "    for l in new_links:\n",
    "        if l in possible_links:\n",
    "            eva_g.add_edge(l[0], l[1])\n",
    "        elif l in weak_links:\n",
    "            eva_g.remove_edge(l[0], l[1])\n",
    "            \n",
    "    for node in disc_nodes:\n",
    "        marg = 0\n",
    "        egonet = list(eva_g.neighbors(node)) + [node]\n",
    "        egonet_attrs = [attrs[n] for n in egonet]\n",
    "        count = dict(Counter(egonet_attrs))[attr]\n",
    "        size = len(egonet)\n",
    "        if size > 2:\n",
    "            marg = ((count * weights[attr] / (count * weights[attr] + (size-count)* (1 - weights[attr]))) - 0.5) * 2\n",
    "            fair_marg.append(abs(marg))\n",
    "            if abs(marg) > threshold:\n",
    "                nodes += 1\n",
    "    \n",
    "        \n",
    "    budget = sum(individual)\n",
    "    \n",
    "    if return_net:\n",
    "        return nodes, np.mean(fair_marg), budget, eva_g\n",
    "    \n",
    "    if fitness == 'nodes':      \n",
    "        return nodes, budget\n",
    "    elif fitness == 'marg':\n",
    "        return np.mean(fair_marg), budget\n",
    "    else:\n",
    "        print (\"ERROR #03\")\n",
    "        \n",
    "\n",
    "\n",
    "    #Fitness 1: nodi marginalizzati rimasti\n",
    "    #Fitness 2: link usati\n",
    "    \n",
    "    #A parità di nodi marginalizzati (il meno possibile), la soluzione con meno link usati è la migliore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf6791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_net = False #if True, eva function returns the fair network. INSIDE THE GA, IT MUST BE FALSE\n",
    "\n",
    "creator.create(\"Fitness\", base.Fitness, weights=(-1.0,-1.0)) # <- -1 perché vogliamo minimizzare la fitness\n",
    "creator.create(\"Individual\", list, fitness=creator.Fitness) #<- l'individuo è definito come lista\n",
    "\n",
    "toolbox = base.Toolbox() #creiamo il toolbox\n",
    "\n",
    "toolbox.register(\"random_individual\", random_individual, links) \n",
    "#\"nome_della_funzione per deap\", nome_della_funzione vera e propria di python, parametri che passi alla funzione\n",
    "\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, \n",
    "                 toolbox.random_individual, n=1) \n",
    "# n = numero di individui nella popolazione. Lasciamo 1\n",
    "\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate, g=g, return_net=return_net) #funzione di valutazione. Vedi quanto detto sopra\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint) #funzione di crossover\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05) #funzione di mutazione custom\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "#tools.selNSGA2) #funzione di selezione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6fac1a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Marg nodes:', disc, '· Marg Score:', ov_marg, '· Available links:', len(links))\n",
    "print('Fitness:', fitness)\n",
    "NUM_GENERATIONS = 150 #numero di generazioni\n",
    "POPULATION_SIZE = 150 #popolazione per gen\n",
    "\n",
    "CXPB, MUTPB = 0.5, 0.25 #crossover e mutation probability\n",
    "\n",
    "n_HOF = 10 #top soluzioni da ritornare (la \"Hall of Fame\" di DEAP è il set di tutte le top n soluzioni)\n",
    "\n",
    "pop = toolbox.population(n=POPULATION_SIZE)\n",
    "\n",
    "hof = tools.HallOfFame(n_HOF)\n",
    "\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values[0])   \n",
    "stats.register('min', np.min, axis = 0)\n",
    "stats.register('avg', np.mean, axis = 0)\n",
    "\n",
    "logbook = tools.Logbook()\n",
    "logbook.header = ['gen', 'nevals'] + stats.fields\n",
    "\n",
    "invalid_individuals = [ind for ind in pop if not ind.fitness.valid]\n",
    "fitnesses = toolbox.map(toolbox.evaluate, invalid_individuals)\n",
    "for ind, fit in zip(invalid_individuals, fitnesses):\n",
    "    ind.fitness.values = fit\n",
    "\n",
    "hof.update(pop)\n",
    "hof_size = len(hof.items)\n",
    "\n",
    "record = stats.compile(pop)\n",
    "logbook.record(gen=0, best=\"-\", nevals=len(invalid_individuals), **record)\n",
    "print(logbook.stream)\n",
    "\n",
    "for gen in range(1, NUM_GENERATIONS + 1):\n",
    "\n",
    "            # Select the next generation individuals\n",
    "    offspring = toolbox.select(pop, len(pop))\n",
    "    # Clone the selected individuals\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "\n",
    "    # Apply crossover and mutation on the offspring\n",
    "    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if random.random() < CXPB:\n",
    "            toolbox.mate(child1[0], child2[0])\n",
    "            del child1.fitness.values\n",
    "            del child2.fitness.values\n",
    "\n",
    "    for mutant in offspring:\n",
    "        if random.random() < MUTPB:\n",
    "            toolbox.mutate(mutant[0])\n",
    "            del mutant.fitness.values\n",
    "\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    fitnesses = map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    # Update the hall of fame with the generated individuals\n",
    "    hof.update(offspring)\n",
    "\n",
    "    # Replace the current population by the offspring\n",
    "    pop[:] = offspring\n",
    "\n",
    "    # Append the current generation statistics to the logbook\n",
    "    record = stats.compile(pop) if stats else {}\n",
    "    logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "    print(logbook.stream)\n",
    "\n",
    "\n",
    "hof.update(pop) # la HoF è aggiornata con la nuova popolazione (o meglio, i suoi individui migliori w.r.t. fitness)\n",
    "\n",
    "plt.figure(1)\n",
    "\n",
    "minFitnessValues, meanFitnessValues = logbook.select(\"min\", \"avg\")\n",
    "plt.figure(2)\n",
    "sns.set_style(\"whitegrid\")\n",
    "#plt.plot(maxFitnessValues, color='red')\n",
    "plt.plot(minFitnessValues, color='blue')\n",
    "plt.plot(meanFitnessValues, color='green')\n",
    "plt.xlabel('Generation')\n",
    "if fitness == 'nodes':\n",
    "    plt.ylabel('Marginalized Nodes')\n",
    "    plt.title('Avg and Min Marginalized Nodes')\n",
    "elif fitness == 'marg':\n",
    "    plt.ylabel('Marginalization Score')\n",
    "    plt.title('Avg and Min Marginalization Score')    \n",
    "# show both plots:\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#return hof.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a0c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = hof.items[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb484a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_nodes, fair_score, fair_budget, fair_net = evaluate([best], g, True)\n",
    "\n",
    "print (\"Marg Nodes:\", fair_nodes, '· Prev:', len(disc_nodes))\n",
    "print (\"Marg Score:\", fair_score, '· Prev:', ov_marg)\n",
    "print (\"Links:\", fair_net.number_of_edges(), '· Prev:', g.number_of_edges())\n",
    "if mode == 0:\n",
    "    print (\"Added links:\", fair_budget)\n",
    "elif mode == 1:\n",
    "    print (\"Removed links:\", fair_budget)\n",
    "elif mode == 2:\n",
    "    print (\"Modified links:\", fair_budget)\n",
    "    added = fair_net.number_of_edges() - g.number_of_edges()\n",
    "    print (\"-- of which added:\", added)\n",
    "    print (\"-- of which removed:\", fair_budget - added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002ff23b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7f8cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for e in hof.items[:3]:\n",
    " #   print('Marginalized nodes:', e.fitness.values[0], '· Links:', e.fitness.values[1], '· Percentage:', e.fitness.values[1]/g.number_of_edges())\n",
    "  #  print(e[0])\n",
    "   # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123412de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#index = [i for i, j in enumerate(best) if j == 1]\n",
    "#new_links = [links[i] for i in index]\n",
    "\n",
    "#new_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad555008",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RandNet - A Random Benchmark for FairNet\")\n",
    "nodes_ran = []\n",
    "score_ran = []\n",
    "c = 0\n",
    "while c < 100:\n",
    "    ran = random_individual(links)\n",
    "    fair_nodes, fair_score, fair_budget, fair_net = evaluate([ran], g, True)\n",
    "    nodes_ran.append(fair_nodes)\n",
    "    score_ran.append(fair_score)\n",
    "    c = c+1\n",
    "\n",
    "print(\"- Marg nodes\")\n",
    "print(\"Avg:\", np.mean(nodes_ran), \"· Min:\", min(nodes_ran))\n",
    "print(\"- Marg score\")\n",
    "print(\"Avg:\", np.mean(score_ran), \"· Min:\", min(score_ran))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ae4caa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
