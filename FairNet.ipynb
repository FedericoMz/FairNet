{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66acfb85-2b23-40e3-b57d-4af082868917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "from statistics import mean\n",
    "import community\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "import random\n",
    "import copy\n",
    "\n",
    "\n",
    "from deap import base\n",
    "from deap import creator\n",
    "from deap import tools\n",
    "from math import dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee362f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.3\n",
    "egoradius = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2007c150",
   "metadata": {},
   "source": [
    "# AMARE - Attribute-aware MARginalization Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e725c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(node, node_to_com, com_to_nodes):\n",
    "    node_com_id = node_to_com[node]\n",
    "    com = com_to_nodes[node_com_id]\n",
    "    net = nx.subgraph(g, com)\n",
    "    count = dict(Counter(list(nx.get_node_attributes(net, 'gender').values())))\n",
    "    if '0' in count:\n",
    "        males = count['0']\n",
    "    else:\n",
    "        males = 0\n",
    "    if '1' in count:\n",
    "        females = count['1']\n",
    "    else:\n",
    "        females = 0\n",
    "        \n",
    "    if attrs[node] == '1':\n",
    "        return 1 - females / len(com)\n",
    "    else:\n",
    "        return 1 - males / len(com)\n",
    "    \n",
    "    print(f'com size: {len(com)}, males: {males}, females: {females}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c890509-942f-4750-ba01-98f1e5fcaecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g = nx.Graph()\n",
    "g.name = 'copenhagen'\n",
    "with open('bt_symmetric.csv') as f:\n",
    "    for l in f.readlines()[1:]:\n",
    "        tid, a, b, rssi = l.rstrip().split(',')\n",
    "        g.add_edge(int(a),int(b), tid=tid)\n",
    "print('loaded')\n",
    "\n",
    "attrs = {n: None for n in g.nodes()} # also fix missing data\n",
    "with open('genders.csv') as f:\n",
    "    for l in f.readlines()[1:]:\n",
    "        node, gender = l.rstrip().split(',')\n",
    "        attrs[int(node)] = gender\n",
    "    nx.set_node_attributes(g, attrs, name='gender')\n",
    "print('attributes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0c724d-778f-43ba-b115-7513957b18b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_remove = []\n",
    "for n in attrs:\n",
    "    if attrs[n] is None:\n",
    "        to_remove.append(n)\n",
    "\n",
    "g.remove_nodes_from(to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6e85f7-0c4e-41b3-838f-6b680104bc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx.info(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e79485",
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = nx.get_node_attributes(g, 'gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a55fed-fc80-4768-a6ab-0d6b989fe9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#g = nx.convert_node_labels_to_integers(g)\n",
    "sizes = dict(Counter(list(nx.get_node_attributes(g, 'gender').values())))\n",
    "sizes['0'] = sizes['0'] / (len(g))\n",
    "sizes['1'] = sizes['1'] / (len(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41a25d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = dict(Counter(list(nx.get_node_attributes(g, 'gender').values())))\n",
    "weights['0'] = 1 - sizes['0']\n",
    "weights['1'] = 1 - sizes['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3ca4d9-70b6-462c-9cdc-e25b13fc3e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def homogeneity(node, attr, center=True):\n",
    "    \n",
    "    egonet = nx.ego_graph(g, node, center=center)\n",
    "    egonet_attrs = list(nx.get_node_attributes(egonet, 'gender').values())\n",
    "    count = dict(Counter(egonet_attrs))[attr]\n",
    "    size = len(egonet)\n",
    "    if size > 2:\n",
    "        return count/size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0fd357-e21c-4da5-8448-eeb01a182196",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "margs = []\n",
    "\n",
    "marg_dict = dict()\n",
    "\n",
    "for node in list(g.nodes()):\n",
    "    attr = attrs[node]\n",
    "    \n",
    "    # COMPUTE MARGINALIZATION\n",
    "    marg = 0\n",
    "    egonet = nx.ego_graph(g, node, center=True)\n",
    "    egonet_attrs = list(nx.get_node_attributes(egonet, 'gender').values())\n",
    "    \n",
    "    #try\n",
    "    count = dict(Counter(egonet_attrs))[attr]\n",
    "    #except:\n",
    "    #count = 0\n",
    "    \n",
    "    size = len(egonet)\n",
    "    if size > 2:\n",
    "        marg = ((count * weights[attr] / (count * weights[attr] + (size-count)* (1 - weights[attr]))) - 0.5) * 2\n",
    "        margs.append(marg)  \n",
    "        if abs(marg) > threshold:\n",
    "            marg_dict[node] = marg        \n",
    "        else:\n",
    "            marg_dict[node] = 0\n",
    "    else:\n",
    "        marg_dict[node] = 0\n",
    "\n",
    "disc_nodes = [k for k,v in marg_dict.items() if abs(v) > threshold]\n",
    "disc = len(disc_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f335af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plausible = nx.Graph() # stores plausible links\n",
    "for node in disc_nodes:\n",
    "    egonet = nx.ego_graph(g, node, center=True)\n",
    "    egonet2 = nx.ego_graph(g, node, center=True, radius=egoradius)\n",
    "    egonet2.remove_nodes_from(egonet)\n",
    "    for n in egonet2.nodes():\n",
    "        if node != n and n in disc_nodes:\n",
    "            if marg_dict[node] > 0:\n",
    "                if attrs[n] != attrs[node]:\n",
    "                    plausible.add_edge(node, n)\n",
    "            elif marg_dict[node] < 0:\n",
    "                if attrs[n] == attrs[node]:\n",
    "                    plausible.add_edge(node, n)         \n",
    "            else:\n",
    "                print (\"ERROR\")\n",
    "links = list(plausible.edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd35a76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== STATS ===\")\n",
    "print(\"Marginalized nodes:\", disc)\n",
    "print(\"Global Discrimination:\", disc * 100 / len(g.nodes()))\n",
    "print(\"Overall Marginalization Score:\", mean([abs(x) for x in marg_dict.values()]))\n",
    "sns.kdeplot(margs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3820b77d",
   "metadata": {},
   "source": [
    "# MASK - MArginalization Shrinking using linK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bcceb0-989b-4d0d-a8a2-506f6aeaa4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_individual(links):\n",
    "    \n",
    "    individual = []\n",
    "    \n",
    "    for e in links:\n",
    "        individual.append(random.randint(0,1))\n",
    "    \n",
    "\n",
    "    return individual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae8f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(individual, g):\n",
    "    \n",
    "    eva = 0\n",
    "    \n",
    "    eva_g = copy.deepcopy(g)\n",
    "    \n",
    "    individual = individual[0] #<- because DEAP\n",
    "    \n",
    "    nodes = set()\n",
    "\n",
    "    \n",
    "    index = [i for i, j in enumerate(individual) if j == 1]\n",
    "\n",
    "    new_links = [links[i] for i in index]\n",
    "\n",
    "    #print (new_links)\n",
    "    for l in new_links:\n",
    "        eva_g.add_edge(l[0], l[1])\n",
    "            \n",
    "    for node in disc_nodes:\n",
    "        marg = 0\n",
    "        egonet = nx.ego_graph(eva_g, node, center=True)\n",
    "        egonet_attrs = list(nx.get_node_attributes(egonet, 'gender').values())\n",
    "        #try:\n",
    "        count = dict(Counter(egonet_attrs))[attr]\n",
    "        #except:\n",
    "         #   count = 0\n",
    "        \n",
    "        size = len(egonet)\n",
    "        if size > 2:\n",
    "            marg = ((count * weights[attr] / (count * weights[attr] + (size-count)* (1 - weights[attr]))) - 0.5) * 2\n",
    "            if abs(marg) > threshold:\n",
    "                eva = eva+1\n",
    "                \n",
    "        \n",
    "    budget = sum(individual)\n",
    "            \n",
    "    return eva, budget, \n",
    "\n",
    "    #Fitness 1: nodi marginalizzati rimasti\n",
    "    #Fitness 2: link usati\n",
    "    \n",
    "    #A parità di nodi marginalizzati (il meno possibile), la soluzione con meno link usati è la migliore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf6791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "creator.create(\"Fitness\", base.Fitness, weights=(-1.0,-1.0)) # <- -1 perché vogliamo minimizzare la fitness\n",
    "creator.create(\"Individual\", list, fitness=creator.Fitness) #<- l'individuo è definito come lista\n",
    "\n",
    "toolbox = base.Toolbox() #creiamo il toolbox\n",
    "\n",
    "toolbox.register(\"random_individual\", random_individual, links) \n",
    "#\"nome_della_funzione per deap\", nome_della_funzione vera e propria di python, parametri che passi alla funzione\n",
    "\n",
    "toolbox.register(\"individual\", tools.initRepeat, creator.Individual, \n",
    "                 toolbox.random_individual, n=1) \n",
    "# n = numero di individui nella popolazione. Lasciamo 1\n",
    "\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "\n",
    "toolbox.register(\"evaluate\", evaluate, g=g) #funzione di valutazione. Vedi quanto detto sopra\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint) #funzione di crossover\n",
    "toolbox.register(\"mutate\", tools.mutFlipBit, indpb=0.05) #funzione di mutazione custom\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "#tools.selNSGA2) #funzione di selezione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bf8502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6fac1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#def GA():\n",
    "print ('Marginalized nodes:', disc, '· Available links:', len(links))\n",
    "NUM_GENERATIONS = 50 #numero di generazioni\n",
    "POPULATION_SIZE = 150 #popolazione per gen\n",
    "\n",
    "CXPB, MUTPB = 0.5, 0.25 #crossover e mutation probability\n",
    "\n",
    "n_HOF = 10 #top soluzioni da ritornare (la \"Hall of Fame\" di DEAP è il set di tutte le top n soluzioni)\n",
    "\n",
    "pop = toolbox.population(n=POPULATION_SIZE)\n",
    "\n",
    "hof = tools.HallOfFame(n_HOF)\n",
    "\n",
    "stats = tools.Statistics(lambda ind: ind.fitness.values[0])   \n",
    "stats.register('min', np.min, axis = 0)\n",
    "stats.register('avg', np.mean, axis = 0)\n",
    "\n",
    "logbook = tools.Logbook()\n",
    "logbook.header = ['gen', 'nevals'] + stats.fields\n",
    "\n",
    "invalid_individuals = [ind for ind in pop if not ind.fitness.valid]\n",
    "fitnesses = toolbox.map(toolbox.evaluate, invalid_individuals)\n",
    "for ind, fit in zip(invalid_individuals, fitnesses):\n",
    "    ind.fitness.values = fit\n",
    "\n",
    "hof.update(pop)\n",
    "hof_size = len(hof.items)\n",
    "\n",
    "record = stats.compile(pop)\n",
    "logbook.record(gen=0, best=\"-\", nevals=len(invalid_individuals), **record)\n",
    "print(logbook.stream)\n",
    "\n",
    "for gen in range(1, NUM_GENERATIONS + 1):\n",
    "\n",
    "            # Select the next generation individuals\n",
    "    offspring = toolbox.select(pop, len(pop))\n",
    "    # Clone the selected individuals\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "\n",
    "    # Apply crossover and mutation on the offspring\n",
    "    for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if random.random() < CXPB:\n",
    "            toolbox.mate(child1[0], child2[0])\n",
    "            del child1.fitness.values\n",
    "            del child2.fitness.values\n",
    "\n",
    "    for mutant in offspring:\n",
    "        if random.random() < MUTPB:\n",
    "            toolbox.mutate(mutant[0])\n",
    "            del mutant.fitness.values\n",
    "\n",
    "\n",
    "    # Evaluate the individuals with an invalid fitness\n",
    "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    fitnesses = map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "\n",
    "    # Update the hall of fame with the generated individuals\n",
    "    hof.update(offspring)\n",
    "\n",
    "    # Replace the current population by the offspring\n",
    "    pop[:] = offspring\n",
    "\n",
    "    # Append the current generation statistics to the logbook\n",
    "    record = stats.compile(pop) if stats else {}\n",
    "    logbook.record(gen=gen, nevals=len(invalid_ind), **record)\n",
    "    print(logbook.stream)\n",
    "\n",
    "\n",
    "hof.update(pop) # la HoF è aggiornata con la nuova popolazione (o meglio, i suoi individui migliori w.r.t. fitness)\n",
    "\n",
    "plt.figure(1)\n",
    "\n",
    "minFitnessValues, meanFitnessValues = logbook.select(\"min\", \"avg\")\n",
    "plt.figure(2)\n",
    "sns.set_style(\"whitegrid\")\n",
    "#plt.plot(maxFitnessValues, color='red')\n",
    "plt.plot(minFitnessValues, color='blue')\n",
    "plt.plot(meanFitnessValues, color='green')\n",
    "plt.xlabel('Generation')\n",
    "plt.ylabel('Fitness Value')\n",
    "plt.title('Avg and Min Fitness')\n",
    "# show both plots:\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#return hof.items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25db85da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7f8cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in hof.items:\n",
    "    print ('Marginalized nodes:', e.fitness.values[0], '· Links:', e.fitness.values[1])\n",
    "    print (e[0])\n",
    "    print (\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123412de",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = hof.items[0][0]\n",
    "\n",
    "index = [i for i, j in enumerate(best) if j == 1]\n",
    "\n",
    "new_links = [links[i] for i in index]\n",
    "\n",
    "new_links"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63017c10",
   "metadata": {},
   "source": [
    "Random Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad555008",
   "metadata": {},
   "outputs": [],
   "source": [
    "rans = []\n",
    "c = 0\n",
    "print (\"Marginalized nodes:\", end = ' ')\n",
    "while c < 100:\n",
    "    ran = random_individual (links)\n",
    "    print (evaluate([ran], g)[0], end = ' ')\n",
    "    rans.append(evaluate([ran], g)[0])\n",
    "    c = c+1\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "print(\"Avg:\", mean(rans), \"· Min:\", min(rans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0078ad4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715c7ffe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
